{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import audioop\n",
    "import itertools\n",
    "import pathlib\n",
    "import random\n",
    "import subprocess\n",
    "import tempfile\n",
    "import wave\n",
    "\n",
    "import keras.models\n",
    "import numpy as np\n",
    "import tgt\n",
    "import webrtcvad\n",
    "\n",
    "import floor_control\n",
    "import skantze_train\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUEL_DIR = pathlib.Path('~/DUEL').expanduser()\n",
    "SUB_DUEL_DIR = DUEL_DIR / 'de'\n",
    "ANNOTATIONS_DIR =  SUB_DUEL_DIR / 'transcriptions_annotations'\n",
    "AUDIO_DIR = SUB_DUEL_DIR / 'audio'\n",
    "BUFFER_DURATION = 0.02\n",
    "BACKCHANNEL_WORDS = {'ja', 'okay', 'ohm', 'mhm', 'genau'}\n",
    "MAX_BACKCHANNEL_DURATION = 0.5\n",
    "ANNOTATIONS_TIERS = ['A-utts', 'B-utts']\n",
    "SWAPPED_STEREO = {'r12', 'r13', 'r16'}\n",
    "COMPARABLE_TIERS = ['detected', 'random', 'vad', 'skantze']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(annotations_dir):\n",
    "    tgs = {}\n",
    "    for session_dir in annotations_dir.glob('r*'):\n",
    "        filepath = next(session_dir.glob('r*.TextGrid'))\n",
    "        tgs[session_dir.name] = tgt.io.read_textgrid(filepath)\n",
    "    return tgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgrids = load_data(ANNOTATIONS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floor tier from annotations (target / annotated floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_unsorted_utterance_intervals(tg, tier_names):\n",
    "    for i, tier in enumerate(tier_names):\n",
    "        for interval in tg.get_tier_by_name(tier).intervals:\n",
    "            yield tgt.core.Interval(\n",
    "                interval.start_time,\n",
    "                interval.end_time,\n",
    "                str(i),\n",
    "            )\n",
    "\n",
    "\n",
    "def _generate_floor_intervals(tg, tier_names):\n",
    "    gen = _generate_unsorted_utterance_intervals(tg, tier_names)\n",
    "    intervals = iter(sorted(gen, key=lambda x: x.start_time))\n",
    "    cur = next(intervals)\n",
    "    while True:\n",
    "        try:\n",
    "            nex = next(intervals)\n",
    "        except StopIteration:\n",
    "            yield cur\n",
    "            break\n",
    "        # Current and next one are same speaker -> merge\n",
    "        if cur.text == nex.text:\n",
    "            cur = tgt.core.Interval(cur.start_time, nex.end_time, cur.text)\n",
    "        # Current ends before next one starts -> output current\n",
    "        elif cur.end_time <= nex.start_time:\n",
    "            yield cur\n",
    "            cur = nex\n",
    "        # Next is completely within current -> ignore it\n",
    "        elif nex.start_time >= cur.start_time and nex.end_time <= cur.end_time:\n",
    "            pass\n",
    "        # Otherwise it's a partial overlap\n",
    "        else:\n",
    "            yield tgt.core.Interval(cur.start_time, nex.start_time, cur.text)\n",
    "            cur = tgt.core.Interval(cur.end_time, nex.end_time, nex.text)\n",
    "            \n",
    "            \n",
    "def calculate_floor_tier_from_annotations(tg, tier_names):\n",
    "    floor_tier = tgt.core.IntervalTier(name='target')\n",
    "    floor_tier.add_intervals(_generate_floor_intervals(tg, tier_names))\n",
    "    return floor_tier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backchannels tier from annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_backchannel(interval):\n",
    "    words = [w.lower() for w in interval.text.split()]\n",
    "    backchannel_words = all(w in BACKCHANNEL_WORDS for w in words)\n",
    "    short_enough = interval.end_time - interval.start_time < MAX_BACKCHANNEL_DURATION\n",
    "    return backchannel_words and short_enough\n",
    "\n",
    "\n",
    "def _generate_backchannel_points(tg, tier_names):\n",
    "    for i, tier_name in enumerate(tier_names):\n",
    "        for interval in tg.get_tier_by_name(tier_name).intervals:\n",
    "            if is_backchannel(interval):\n",
    "                yield tgt.core.Point(time=interval.start_time, text=str(i))\n",
    "\n",
    "\n",
    "def calculate_backchannels_tier_from_annotations(tg, tier_names):\n",
    "    backchannels_tier = tgt.core.PointTier(name='backchannels')\n",
    "    backchannels_tier.add_points(_generate_backchannel_points(tg, tier_names))\n",
    "    return backchannels_tier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floor tier from audio (detected / FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_detection_per_frame_from_wav(\n",
    "    filepath,\n",
    "    buffer_duration,\n",
    "    swap_stereo,\n",
    "    detector_class,\n",
    "    detector_params,\n",
    "):\n",
    "    with wave.open(str(filepath)) as f:\n",
    "        sample_rate = f.getframerate()\n",
    "        sample_width = f.getsampwidth()\n",
    "        buffer_size = int(sample_rate * buffer_duration)\n",
    "\n",
    "        detector_params['sample_rate'] = sample_rate\n",
    "        detector_params['sample_width'] = sample_width\n",
    "        detector_params['buffer_size'] = buffer_size\n",
    "\n",
    "        detector = detector_class(**detector_params)\n",
    "\n",
    "        while True:\n",
    "            fragment = f.readframes(buffer_size)\n",
    "            if len(fragment) != buffer_size * sample_width * f.getnchannels():\n",
    "                break\n",
    "            l = audioop.tomono(fragment, sample_width, 1, 0)\n",
    "            r = audioop.tomono(fragment, sample_width, 0, 1)\n",
    "            if swap_stereo:\n",
    "                l, r = r, l\n",
    "            yield detector.process([l, r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_intervals_from_frames(frames, frame_duration, shift=0):\n",
    "    timed_frames = zip(itertools.count(step=frame_duration), frames)\n",
    "    changes = utils.dedup(timed_frames, key=lambda x: x[1])\n",
    "    for cur, nex in utils.pairwise(changes):\n",
    "        yield tgt.core.Interval(start_time=cur[0] + shift, end_time=nex[0] + shift, text=str(cur[1]))\n",
    "    \n",
    "    \n",
    "def frames_to_tier(frames, buffer_duration, tier_name):\n",
    "    intervals = generate_intervals_from_frames(frames, buffer_duration)\n",
    "    tier = tgt.core.IntervalTier(name=tier_name)\n",
    "    tier.add_intervals(intervals)\n",
    "    return tier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random floor tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_random_floor_intervals(average_floor_duration):\n",
    "    floor_holder = random.randint(0, 1)\n",
    "    previous_timestamp = 0\n",
    "    while True:\n",
    "        samples = np.random.exponential(average_floor_duration, 100)\n",
    "        timestamps = samples.cumsum() + previous_timestamp\n",
    "        for timestamp in timestamps:\n",
    "            yield tgt.core.Interval(\n",
    "                start_time=previous_timestamp,\n",
    "                end_time=timestamp,\n",
    "                text=str(floor_holder)\n",
    "            )\n",
    "            floor_holder = (floor_holder * -1) + 1\n",
    "            previous_timestamp = timestamp\n",
    "\n",
    "\n",
    "def calculate_random_floor_tier(average_floor_duration, textgrid_duration):\n",
    "    gen = _generate_random_floor_intervals(average_floor_duration)\n",
    "    tier = tgt.core.IntervalTier(name='random')\n",
    "    tier.add_intervals(itertools.takewhile(lambda i: i.end_time < textgrid_duration, gen))\n",
    "    return tier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAD floor tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VadDetector:\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_rate,\n",
    "        vad_mode,\n",
    "        **_,\n",
    "    ):\n",
    "        self._vad = webrtcvad.Vad(vad_mode)\n",
    "        self._sample_rate = sample_rate\n",
    "        self._current_floor_holder = None\n",
    "        \n",
    "    def process(self, fragments):\n",
    "        vad_vals = [self._vad.is_speech(fragment, self._sample_rate) for fragment in fragments]\n",
    "        # Change floor holder when only one is vocalising\n",
    "        if sum(vad_vals) == 1:\n",
    "            self._current_floor_holder = vad_vals.index(True)\n",
    "        return self._current_floor_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(source, target):\n",
    "    subprocess.run([\n",
    "        'ffmpeg',\n",
    "        '-y',  # Overwrite, it will always exist because a temp is created\n",
    "        '-i', source,\n",
    "        '-ar', '48000',\n",
    "        target,\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update TextGrids with calculated tiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotated floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tg in textgrids.values():\n",
    "    tg.add_tier(calculate_floor_tier_from_annotations(tg, ANNOTATIONS_TIERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotated backchannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tg in textgrids.values():\n",
    "    tg.add_tier(calculate_backchannels_tier_from_annotations(tg, ANNOTATIONS_TIERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55 s, sys: 3.26 s, total: 58.3 s\n",
      "Wall time: 58.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for session, tg in textgrids.items():\n",
    "    audio_filepath = AUDIO_DIR / session / f'{session}.wav'\n",
    "    frames_gen = generate_detection_per_frame_from_wav(\n",
    "        audio_filepath,\n",
    "        BUFFER_DURATION,\n",
    "        session in SWAPPED_STEREO,\n",
    "        floor_control.RmsFilterDetector,\n",
    "        {'cutoff_freq': 0.35, 'hysteresis': 0.1},\n",
    "    )\n",
    "    tg.add_tier(frames_to_tier(list(frames_gen), BUFFER_DURATION, 'detected'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2634707847988684"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_floor_duration = np.mean(\n",
    "    [\n",
    "        i.end_time - i.start_time\n",
    "        for tg in textgrids.values()\n",
    "        for i in tg.get_tier_by_name('target')\n",
    "    ]\n",
    ")\n",
    "average_floor_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tg in textgrids.values():\n",
    "    tg.add_tier(calculate_random_floor_tier(average_floor_duration, tg.end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skantze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.nan_to_num(np.load('X.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0806 10:56:55.347461 140551529911936 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0806 10:56:55.358261 140551529911936 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0806 10:56:55.360572 140551529911936 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0806 10:56:55.514609 140551529911936 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0806 10:56:55.515134 140551529911936 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0806 10:56:55.602610 140551529911936 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0806 10:56:55.813566 140551529911936 deprecation.py:323] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model_0 = keras.models.load_model('model_0.h5')\n",
    "model_1 = keras.models.load_model('model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 25s, sys: 9.17 s, total: 2min 34s\n",
      "Wall time: 56.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "idx = 0\n",
    "for _, textgrid in sorted(textgrids.items()):\n",
    "    intervals = []\n",
    "    for part in textgrid.get_tier_by_name('Part').intervals:\n",
    "        start_time = part.start_time\n",
    "        end_time = part.end_time\n",
    "        n_frames = int(end_time - start_time) * 20\n",
    "        part_X = X[idx:idx + n_frames]\n",
    "        batch_generator = skantze_train.BatchGenerator(\n",
    "            part_X,\n",
    "            y=np.zeros(len(X)),  # Unused but still needed\n",
    "            sequence_length=skantze_train.SEQUENCE_LENGTH,\n",
    "            batch_size=skantze_train.BATCH_SIZE,\n",
    "        )\n",
    "        model_0_predictions = model_0.predict_generator(batch_generator)\n",
    "        model_1_predictions = model_1.predict_generator(batch_generator)\n",
    "        predictions = np.hstack([model_0_predictions, model_1_predictions])\n",
    "        floor_holder = predictions.argmax(axis=1)\n",
    "        intervals += list(\n",
    "            generate_intervals_from_frames(\n",
    "                floor_holder,\n",
    "                frame_duration=0.05,\n",
    "                shift=start_time\n",
    "            )\n",
    "        )\n",
    "        idx += n_frames\n",
    "    tier = tgt.core.IntervalTier(name='skantze')\n",
    "    tier.add_intervals(intervals)\n",
    "    textgrid.add_tier(tier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 3.04 s, total: 1min 26s\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for session, tg in textgrids.items():\n",
    "    audio_filepath = AUDIO_DIR / session / f'{session}.wav'\n",
    "    with tempfile.NamedTemporaryFile(suffix='.wav') as tf:\n",
    "        upsample(str(audio_filepath.resolve()), tf.name)\n",
    "        frames_gen = generate_detection_per_frame_from_wav(\n",
    "            tf.name,\n",
    "            BUFFER_DURATION,\n",
    "            session in SWAPPED_STEREO,\n",
    "            VadDetector,\n",
    "            {'vad_mode': 3},\n",
    "        )\n",
    "        tg.add_tier(frames_to_tier(list(frames_gen), BUFFER_DURATION, 'vad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export textgrid for manual observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session, textgrid in textgrids.items():\n",
    "    with open(pathlib.Path('tmp') / f'{session}.textgrid', 'w') as f:\n",
    "        f.write(tgt.io.export_to_long_textgrid(textgrid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 - agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agreement(target_tier, candidate_tier):\n",
    "    total = 0\n",
    "    hits = 0\n",
    "    for time in itertools.count(step=0.1):\n",
    "        if time > target_tier.end_time:\n",
    "            break\n",
    "        target = target_tier.get_annotations_by_time(time)\n",
    "        if target:\n",
    "            detected = candidate_tier.get_annotations_by_time(time)\n",
    "            if detected and detected[0].text == target[0].text:\n",
    "                hits += 1\n",
    "            total += 1\n",
    "    return hits / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected agreement\n",
      "mean: 0.8438686346523299 std: 0.0390078461939721\n",
      "random agreement\n",
      "mean: 0.5054952034088319 std: 0.019324800066512802\n",
      "vad agreement\n",
      "mean: 0.7504700209529584 std: 0.049604179842404686\n",
      "skantze agreement\n",
      "mean: 0.5828504362735213 std: 0.10529746007058853\n",
      "CPU times: user 2min 46s, sys: 0 ns, total: 2min 46s\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for candidate in COMPARABLE_TIERS:\n",
    "    print(candidate, 'agreement')\n",
    "    vals = [\n",
    "        agreement(t.get_tier_by_name('target'), t.get_tier_by_name(candidate))\n",
    "        for t in textgrids.values()\n",
    "    ]\n",
    "    print('mean:', np.mean(vals), 'std:', np.std(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2 - backchannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backchannels_correctly_categorised(bc_tier, candidate_tier):\n",
    "    total = 0\n",
    "    hits = 0\n",
    "    for bc in bc_tier.points:\n",
    "        floor_at_bc = candidate_tier.get_annotations_by_time(bc.time)\n",
    "        if floor_at_bc:\n",
    "            if floor_at_bc[0].text != bc.text:\n",
    "                hits += 1\n",
    "            total += 1\n",
    "    return hits / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected backchannels correctly categorised\n",
      "mean: 0.8069979228017964 std: 0.08324994883826912\n",
      "random backchannels correctly categorised\n",
      "mean: 0.49876321450211963 std: 0.07112312731291603\n",
      "vad backchannels correctly categorised\n",
      "mean: 0.6064839967832115 std: 0.07092072476182118\n",
      "skantze backchannels correctly categorised\n",
      "mean: 0.5985783627270752 std: 0.1278209531369245\n"
     ]
    }
   ],
   "source": [
    "for candidate in COMPARABLE_TIERS:\n",
    "    print(candidate, 'backchannels correctly categorised')\n",
    "    vals = [\n",
    "        backchannels_correctly_categorised(t.get_tier_by_name('backchannels'), t.get_tier_by_name(candidate))\n",
    "        for t in textgrids.values()\n",
    "    ]\n",
    "    print('mean:', np.mean(vals), 'std:', np.std(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 - stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor_holder_changes(tg, tier_name):\n",
    "    tier = tg.get_tier_by_name(tier_name)\n",
    "    changes = 0\n",
    "    for part in tg.get_tier_by_name('Part').intervals:\n",
    "        start_time = part.start_time\n",
    "        end_time = part.end_time\n",
    "        items = utils.dedup(i.text for i in tier.get_annotations_between_timepoints(start_time, end_time))\n",
    "        changes += len(list(items)) - 1  # number of changes is number of values minus 1\n",
    "    return changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected stability\n",
      "mean: 0.9551751041194774 std: 0.16217969695668932\n",
      "random stability\n",
      "mean: 0.8918649510323112 std: 0.26009393384302526\n",
      "vad stability\n",
      "mean: 0.23594985439160923 std: 0.07873030211875032\n",
      "skantze stability\n",
      "mean: 0.24002204809093844 std: 0.054741415982941966\n"
     ]
    }
   ],
   "source": [
    "for candidate in COMPARABLE_TIERS:\n",
    "    print(candidate, 'stability')\n",
    "    vals = [\n",
    "        floor_holder_changes(t, 'target') / floor_holder_changes(t, candidate)\n",
    "        for t in textgrids.values()\n",
    "    ]\n",
    "    print('mean:', np.mean(vals), 'std:', np.std(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4 - lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag(target_tier, candidate_tier):\n",
    "    lags = []\n",
    "    visited_target_intervals = set()\n",
    "    for candidate_interval in candidate_tier.intervals:\n",
    "        target_intervals = target_tier.get_annotations_by_time(candidate_interval.start_time)\n",
    "        if target_intervals:\n",
    "            target_interval = target_intervals[0]\n",
    "            if (\n",
    "                target_interval.text == candidate_interval.text and\n",
    "                target_interval not in visited_target_intervals\n",
    "            ):\n",
    "                lags.append(candidate_interval.start_time - target_interval.start_time)\n",
    "            visited_target_intervals.add(target_interval)\n",
    "    return np.mean(lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected lag\n",
      "mean: 0.4141007091403314 std: 0.0336827035557385\n",
      "random lag\n",
      "mean: 1.600404302903715 std: 0.3662854005786699\n",
      "vad lag\n",
      "mean: 0.4645374361449508 std: 0.10385029644714708\n",
      "skantze lag\n",
      "mean: 1.895935163747057 std: 2.733595731527794\n"
     ]
    }
   ],
   "source": [
    "for candidate in COMPARABLE_TIERS:\n",
    "    print(candidate, 'lag')\n",
    "    vals = [\n",
    "        lag(t.get_tier_by_name('target'), t.get_tier_by_name(candidate))\n",
    "        for t in textgrids.values()\n",
    "    ]\n",
    "    print('mean:', np.mean(vals), 'std:', np.std(vals))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
