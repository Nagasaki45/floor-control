{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import audioop\n",
    "import itertools\n",
    "import pathlib\n",
    "import random\n",
    "import subprocess\n",
    "import tempfile\n",
    "import wave\n",
    "\n",
    "import keras.models\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from scipy import stats\n",
    "import tgt\n",
    "import webrtcvad\n",
    "\n",
    "import data_loading\n",
    "import floor_control\n",
    "import settings\n",
    "import skantze_train\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(data_loading.generator(settings.ANNOTATIONS_DIR, settings.AUDIO_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotated floor tier from utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_unsorted_utterance_intervals(tg, tier_names):\n",
    "    for i, tier in enumerate(tier_names):\n",
    "        for interval in tg.get_tier_by_name(tier).intervals:\n",
    "            yield tgt.core.Interval(\n",
    "                interval.start_time,\n",
    "                interval.end_time,\n",
    "                str(i),\n",
    "            )\n",
    "\n",
    "\n",
    "def _generate_floor_intervals(tg, tier_names):\n",
    "    gen = _generate_unsorted_utterance_intervals(tg, tier_names)\n",
    "    intervals = iter(sorted(gen, key=lambda x: x.start_time))\n",
    "    cur = next(intervals)\n",
    "    while True:\n",
    "        try:\n",
    "            nex = next(intervals)\n",
    "        except StopIteration:\n",
    "            yield cur\n",
    "            break\n",
    "        # Current and next one are same speaker -> merge\n",
    "        if cur.text == nex.text:\n",
    "            cur = tgt.core.Interval(cur.start_time, nex.end_time, cur.text)\n",
    "        # Current ends before next one starts -> output current\n",
    "        elif cur.end_time <= nex.start_time:\n",
    "            yield cur\n",
    "            cur = nex\n",
    "        # Next is completely within current -> ignore it\n",
    "        elif nex.start_time >= cur.start_time and nex.end_time <= cur.end_time:\n",
    "            pass\n",
    "        # Otherwise it's a partial overlap\n",
    "        else:\n",
    "            yield tgt.core.Interval(cur.start_time, nex.start_time, cur.text)\n",
    "            cur = tgt.core.Interval(cur.end_time, nex.end_time, nex.text)\n",
    "            \n",
    "            \n",
    "def calculate_floor_tier_from_annotations(tg, tier_names):\n",
    "    floor_tier = tgt.core.IntervalTier(name='floor')\n",
    "    floor_tier.add_intervals(_generate_floor_intervals(tg, tier_names))\n",
    "    return floor_tier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backchannels tier from annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_backchannel(interval):\n",
    "    words = [w.lower() for w in interval.text.split()]\n",
    "    backchannel_words = all(w in settings.BACKCHANNEL_WORDS for w in words)\n",
    "    short_enough = interval.end_time - interval.start_time < settings.MAX_BACKCHANNEL_DURATION\n",
    "    return backchannel_words and short_enough\n",
    "\n",
    "\n",
    "def _generate_backchannel_points(tg, tier_names):\n",
    "    for i, tier_name in enumerate(tier_names):\n",
    "        for interval in tg.get_tier_by_name(tier_name).intervals:\n",
    "            if is_backchannel(interval):\n",
    "                yield tgt.core.Point(time=interval.start_time, text=str(i))\n",
    "\n",
    "\n",
    "def calculate_backchannels_tier_from_annotations(tg, tier_names):\n",
    "    backchannels_tier = tgt.core.PointTier(name='backchannels')\n",
    "    backchannels_tier.add_points(_generate_backchannel_points(tg, tier_names))\n",
    "    return backchannels_tier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floor control detection (FCD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_detection_per_frame_from_wav(\n",
    "    filepath,\n",
    "    buffer_duration,\n",
    "    swap_stereo,\n",
    "    detector_class,\n",
    "    detector_params,\n",
    "):\n",
    "    with wave.open(str(filepath)) as f:\n",
    "        sample_rate = f.getframerate()\n",
    "        sample_width = f.getsampwidth()\n",
    "        buffer_size = int(sample_rate * buffer_duration)\n",
    "\n",
    "        detector_params['sample_rate'] = sample_rate\n",
    "        detector_params['sample_width'] = sample_width\n",
    "        detector_params['buffer_duration'] = buffer_duration\n",
    "\n",
    "        detector = detector_class(**detector_params)\n",
    "\n",
    "        while True:\n",
    "            fragment = f.readframes(buffer_size)\n",
    "            if len(fragment) != buffer_size * sample_width * f.getnchannels():\n",
    "                break\n",
    "            l = audioop.tomono(fragment, sample_width, 1, 0)\n",
    "            r = audioop.tomono(fragment, sample_width, 0, 1)\n",
    "            if swap_stereo:\n",
    "                l, r = r, l\n",
    "            yield detector.process([l, r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_intervals_from_frames(frames, frame_duration, shift=0):\n",
    "    timed_frames = zip(itertools.count(step=frame_duration), frames)\n",
    "    changes = utils.dedup(timed_frames, key=lambda x: x[1])\n",
    "    for cur, nex in utils.pairwise(changes):\n",
    "        yield tgt.core.Interval(start_time=cur[0] + shift, end_time=nex[0] + shift, text=str(cur[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fcd_tier(session, cutoff_freq=0.35, hysteresis=0.1):\n",
    "    tg = session['textgrid']\n",
    "    audio_filepath = settings.AUDIO_DIR / session['name'] / f'{session[\"name\"]}.wav'\n",
    "    frames_gen = generate_detection_per_frame_from_wav(\n",
    "        audio_filepath,\n",
    "        settings.BUFFER_DURATION,\n",
    "        session['swapped_stereo'],\n",
    "        floor_control.FloorControlDetector,\n",
    "        {'cutoff_freq': cutoff_freq, 'hysteresis': hysteresis},\n",
    "    )\n",
    "    tier = tgt.core.IntervalTier(name='fcd')\n",
    "    tier.add_intervals(generate_intervals_from_frames(frames_gen, settings.BUFFER_DURATION))\n",
    "    return tier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_random_floor_intervals(average_floor_duration):\n",
    "    floor_holder = random.randint(0, 1)\n",
    "    previous_timestamp = 0\n",
    "    while True:\n",
    "        samples = np.random.exponential(average_floor_duration, 100)\n",
    "        timestamps = samples.cumsum() + previous_timestamp\n",
    "        for timestamp in timestamps:\n",
    "            yield tgt.core.Interval(\n",
    "                start_time=previous_timestamp,\n",
    "                end_time=timestamp,\n",
    "                text=str(floor_holder)\n",
    "            )\n",
    "            floor_holder = (floor_holder * -1) + 1\n",
    "            previous_timestamp = timestamp\n",
    "\n",
    "\n",
    "def calculate_random_floor_tier(average_floor_duration, textgrid_duration):\n",
    "    gen = _generate_random_floor_intervals(average_floor_duration)\n",
    "    tier = tgt.core.IntervalTier(name='random')\n",
    "    tier.add_intervals(itertools.takewhile(lambda i: i.end_time < textgrid_duration, gen))\n",
    "    return tier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VadDetector:\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_rate,\n",
    "        vad_mode,\n",
    "        **_,\n",
    "    ):\n",
    "        self._vad = webrtcvad.Vad(vad_mode)\n",
    "        self._sample_rate = sample_rate\n",
    "        self._current_floor_holder = None\n",
    "        \n",
    "    def process(self, fragments):\n",
    "        vad_vals = [self._vad.is_speech(fragment, self._sample_rate) for fragment in fragments]\n",
    "        # Change floor holder when only one is vocalising\n",
    "        if sum(vad_vals) == 1:\n",
    "            self._current_floor_holder = vad_vals.index(True)\n",
    "        return self._current_floor_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(source, target):\n",
    "    subprocess.run([\n",
    "        'ffmpeg',\n",
    "        '-y',  # Overwrite, it will always exist because a temp is created\n",
    "        '-i', source,\n",
    "        '-ar', '48000',\n",
    "        target,\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update TextGrids with calculated tiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotated floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in data:\n",
    "    tg = session['textgrid']\n",
    "    tg.add_tier(calculate_floor_tier_from_annotations(tg, settings.ANNOTATIONS_TIERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of annotated floor without competition for floor control. I.e. defined annotated floor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defined_floor_time_ratio(textgrid, start_time, end_time):\n",
    "    floor_tier = textgrid.get_tier_by_name('floor')\n",
    "    floor_intervals = floor_tier.get_annotations_between_timepoints(start_time, end_time)\n",
    "    defined_time = sum([i.end_time - i.start_time for i in floor_intervals])\n",
    "    return defined_time / (end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8348158639511156 0.003661832575892673\n"
     ]
    }
   ],
   "source": [
    "vals = [\n",
    "    defined_floor_time_ratio(session['textgrid'], part['start_time'], part['end_time'])\n",
    "    for session in data\n",
    "    for part in session['parts']\n",
    "]\n",
    "print(np.mean(vals), np.var(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backchannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in data:\n",
    "    tg = session['textgrid']\n",
    "    tg.add_tier(calculate_backchannels_tier_from_annotations(tg, settings.ANNOTATIONS_TIERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 2.68 s, total: 1min 5s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for session in data:\n",
    "    session['textgrid'].add_tier(create_fcd_tier(session))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2634707847988693"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_floor_duration = np.mean(\n",
    "    [\n",
    "        i.end_time - i.start_time\n",
    "        for session in data\n",
    "        for i in session['textgrid'].get_tier_by_name('floor')\n",
    "    ]\n",
    ")\n",
    "average_floor_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in data:\n",
    "    tg = session['textgrid']\n",
    "    tg.add_tier(calculate_random_floor_tier(average_floor_duration, tg.end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model (Skantze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1122 18:30:51.384323 140330374854464 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1122 18:30:51.397258 140330374854464 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1122 18:30:51.400092 140330374854464 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1122 18:30:51.638414 140330374854464 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1122 18:30:51.639153 140330374854464 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1122 18:30:51.722811 140330374854464 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1122 18:30:51.873265 140330374854464 deprecation.py:323] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model_0 = keras.models.load_model('model_0.h5')\n",
    "model_1 = keras.models.load_model('model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 4s, sys: 8.67 s, total: 2min 12s\n",
      "Wall time: 48.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for session in data:\n",
    "    tg = session['textgrid']\n",
    "    intervals = []\n",
    "    for part in session['parts']:\n",
    "        X = np.load(skantze_train.DATA_DIR / f'X-{session[\"name\"]}-{part[\"name\"]}.npy')\n",
    "\n",
    "        batch_generator = skantze_train.BatchGenerator(\n",
    "            X,\n",
    "            np.zeros(len(X)),\n",
    "            skantze_train.SEQUENCE_LENGTH,\n",
    "            skantze_train.PREDICTION_LENGTH,\n",
    "            skantze_train.BATCH_SIZE,\n",
    "        )\n",
    "        model_0_predictions = model_0.predict_generator(batch_generator)\n",
    "        model_1_predictions = model_1.predict_generator(batch_generator)\n",
    "        predictions = np.vstack([model_0_predictions[:, 0], model_1_predictions[:, 0]])\n",
    "        floor_holder = predictions.T.argmax(axis=1)\n",
    "\n",
    "        intervals += list(\n",
    "            generate_intervals_from_frames(\n",
    "                floor_holder,\n",
    "                frame_duration=1 / skantze_train.FRAME_RATE,\n",
    "                shift=part['start_time'] + (skantze_train.SEQUENCE_LENGTH + 1) / skantze_train.FRAME_RATE,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    tier = tgt.core.IntervalTier(name='lstm')\n",
    "    tier.add_intervals(intervals)\n",
    "    tg.add_tier(tier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 22s, sys: 2.63 s, total: 1min 24s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for session in data:\n",
    "    tg = session['textgrid']\n",
    "    audio_filepath = settings.AUDIO_DIR / session['name'] / f'{session[\"name\"]}.wav'\n",
    "    with tempfile.NamedTemporaryFile(suffix='.wav') as tf:\n",
    "        upsample(str(audio_filepath.resolve()), tf.name)\n",
    "        frames_gen = generate_detection_per_frame_from_wav(\n",
    "            tf.name,\n",
    "            settings.BUFFER_DURATION,\n",
    "            session['swapped_stereo'],\n",
    "            VadDetector,\n",
    "            {'vad_mode': 3},\n",
    "        )\n",
    "        tier = tgt.core.IntervalTier(name='vad')\n",
    "        tier.add_intervals(generate_intervals_from_frames(frames_gen, settings.BUFFER_DURATION))\n",
    "        tg.add_tier(tier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export textgrid for manual observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pathlib.Path('tmp')\n",
    "tmp.mkdir(exist_ok=True)\n",
    "\n",
    "for session in data:\n",
    "    with open(tmp / f'{session[\"name\"]}.textgrid', 'w') as f:\n",
    "        f.write(tgt.io.export_to_long_textgrid(session['textgrid']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_application_generator(data, stat_func, candidate=None, *, create_tier=None):\n",
    "    '''\n",
    "    Applies the `stat_func` to each part in the test set.\n",
    "    Requires either `candidate` or `create_tier` function. Not both.\n",
    "    If a `candidate` is supplied, use the tier with that name.\n",
    "    If `create_tier` function is supplied, pass the session to it\n",
    "    to generate a tier.\n",
    "    '''\n",
    "    assert candidate or create_tier\n",
    "    assert not (candidate and create_tier)\n",
    "    for session in data:\n",
    "        tg = session['textgrid']\n",
    "        for part in session['parts']:\n",
    "            if candidate:\n",
    "                candidate_tier = tg.get_tier_by_name(candidate)\n",
    "            else:\n",
    "                candidate_tier = create_tier(session)\n",
    "            yield stat_func(tg, candidate_tier, part['start_time'], part['end_time'])\n",
    "            \n",
    "            \n",
    "def test_set(data):\n",
    "    return _subset(data, test_set=True)\n",
    "\n",
    "\n",
    "def train_set(data):\n",
    "    return _subset(data, train_set=True)\n",
    "\n",
    "\n",
    "def _subset(data, test_set=False, train_set=False):\n",
    "    new_data = []\n",
    "    i = 0\n",
    "    for session in data:\n",
    "        new_session = session.copy()\n",
    "        new_session['parts'] = []\n",
    "        for part in session['parts']:\n",
    "            if (test_set and (i % 4 == 0)) or (train_set and (i % 4 != 0)):\n",
    "                new_session['parts'].append(part)\n",
    "            i += 1\n",
    "        if new_session['parts']:\n",
    "            new_data.append(new_session)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(tg, candidate_tier, start, end):\n",
    "    total = 0\n",
    "    hits = 0\n",
    "    target_tier = tg.get_tier_by_name('floor')\n",
    "    for time in np.arange(start, end, 0.1):\n",
    "        target = target_tier.get_annotations_by_time(time)\n",
    "        candidate = candidate_tier.get_annotations_by_time(time)\n",
    "        if target and candidate:\n",
    "            if candidate[0].text == target[0].text:\n",
    "                hits += 1\n",
    "            total += 1\n",
    "    return hits / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcd accuracy\n",
      "mean: 0.8653953441990642 std: 0.025179023623290376\n",
      "random accuracy\n",
      "mean: 0.5132850958739504 std: 0.0360503081587073\n",
      "vad accuracy\n",
      "mean: 0.7019965078029801 std: 0.06316885551288656\n",
      "lstm accuracy\n",
      "mean: 0.8882538028620065 std: 0.023900469465904153\n",
      "CPU times: user 36.9 s, sys: 0 ns, total: 36.9 s\n",
      "Wall time: 36.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for candidate in settings.COMPARABLE_TIERS:\n",
    "    print(candidate, 'accuracy')\n",
    "    vals = list(stat_application_generator(test_set(data), accuracy, candidate))\n",
    "    print('mean:', np.mean(vals), 'std:', np.std(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backchannels classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backchannels_correctly_categorised(tg, candidate_tier, start, end):\n",
    "    total = 0\n",
    "    hits = 0\n",
    "    bc_tier = tg.get_tier_by_name('backchannels')\n",
    "    for bc in bc_tier.get_annotations_between_timepoints(start, end):\n",
    "        floor_at_bc = candidate_tier.get_annotations_by_time(bc.time)\n",
    "        if floor_at_bc:\n",
    "            if floor_at_bc[0].text != bc.text:\n",
    "                hits += 1\n",
    "            total += 1\n",
    "    return hits / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcd backchannels correctly categorised\n",
      "mean: 0.7922724314742816 std: 0.10568349102940862\n",
      "random backchannels correctly categorised\n",
      "mean: 0.3701232837246644 std: 0.17207857584268407\n",
      "vad backchannels correctly categorised\n",
      "mean: 0.6561874390236582 std: 0.149850841247541\n",
      "lstm backchannels correctly categorised\n",
      "mean: 0.7555062202648837 std: 0.11290367233063701\n"
     ]
    }
   ],
   "source": [
    "for candidate in settings.COMPARABLE_TIERS:\n",
    "    print(candidate, 'backchannels correctly categorised')\n",
    "    vals = list(stat_application_generator(test_set(data), backchannels_correctly_categorised, candidate))\n",
    "    print('mean:', np.mean(vals), 'std:', np.std(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor_holder_changes(tg, candidate_tier, start_time, end_time):\n",
    "    gen = (i.text for i in candidate_tier.get_annotations_between_timepoints(start_time, end_time))\n",
    "    items = utils.dedup(gen)\n",
    "    return len(list(items)) - 1  # number of changes is number of values minus 1\n",
    "\n",
    "\n",
    "def stability(tg, candidate_tier, start_time, end_time):\n",
    "    annotated_floor = tg.get_tier_by_name('floor')\n",
    "    annotated_floor_changes = floor_holder_changes(tg, annotated_floor, start_time, end_time)\n",
    "    candidate_floor_changes = floor_holder_changes(tg, candidate_tier, start_time, end_time)\n",
    "    return annotated_floor_changes / candidate_floor_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcd stability\n",
      "mean: 0.9287108417871082 std: 0.21944462860850766\n",
      "random stability\n",
      "mean: 0.8948645666159241 std: 0.3256787991338075\n",
      "vad stability\n",
      "mean: 0.21358132690750747 std: 0.07577958923744672\n",
      "lstm stability\n",
      "mean: 0.11742626060041336 std: 0.04443382176501092\n"
     ]
    }
   ],
   "source": [
    "for candidate in settings.COMPARABLE_TIERS:\n",
    "    print(candidate, 'stability')\n",
    "    vals = list(stat_application_generator(test_set(data), stability, candidate))\n",
    "    print('mean:', np.mean(vals), 'std:', np.std(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag(tg, candidate_tier, start_time, end_time):\n",
    "    lags = []\n",
    "    visited_target_intervals = set()\n",
    "    target_tier = tg.get_tier_by_name('floor')\n",
    "    for candidate_interval in candidate_tier.intervals:\n",
    "        target_intervals = target_tier.get_annotations_by_time(candidate_interval.start_time)\n",
    "        if target_intervals:\n",
    "            target_interval = target_intervals[0]\n",
    "            if (\n",
    "                target_interval.text == candidate_interval.text and\n",
    "                target_interval not in visited_target_intervals\n",
    "            ):\n",
    "                lags.append(candidate_interval.start_time - target_interval.start_time)\n",
    "            visited_target_intervals.add(target_interval)\n",
    "    return np.mean(lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcd lag\n",
      "mean: 0.41077566962461864 std: 0.04000523491024262\n",
      "random lag\n",
      "mean: 1.8120902064579862 std: 0.32682680185294954\n",
      "vad lag\n",
      "mean: 0.4767208722773748 std: 0.09355363374067974\n",
      "lstm lag\n",
      "mean: 0.29757926099112136 std: 0.41298518105018533\n"
     ]
    }
   ],
   "source": [
    "for candidate in settings.COMPARABLE_TIERS:\n",
    "    print(candidate, 'lag')\n",
    "    vals = list(stat_application_generator(test_set(data), lag, candidate))\n",
    "    print('mean:', np.mean(vals), 'std:', np.std(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimising parameters for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negative_accuracy_from_model(params, data):\n",
    "\n",
    "    def create_fcd_tier_partial(session):\n",
    "        cutoff_freq, hysteresis = params\n",
    "        return create_fcd_tier(session, cutoff_freq, hysteresis)\n",
    "\n",
    "    generator = stat_application_generator(train_set(data), accuracy, create_tier=create_fcd_tier_partial)\n",
    "    return -np.mean(list(generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -0.894242\n",
      "         Iterations: 28\n",
      "         Function evaluations: 66\n",
      "CPU times: user 1h 29min 50s, sys: 2min 35s, total: 1h 32min 26s\n",
      "Wall time: 1h 34min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "res = optimize.minimize(\n",
    "     get_negative_accuracy_from_model,\n",
    "     [0.35, 0.1],\n",
    "     args=(train_set(data), ),\n",
    "     method='Nelder-Mead',\n",
    "     options={'disp': True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[ 1.66455078, -0.05666016],\n",
       "       [ 1.66455078, -0.05669922],\n",
       "       [ 1.66461914, -0.05668945]]), array([-0.89424184, -0.89424184, -0.89423307]))\n",
       "           fun: -0.8942418423799594\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 66\n",
       "           nit: 28\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([ 1.66455078, -0.05666016])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in data:\n",
    "    optimized_fcd_tier = create_fcd_tier(session, *res.x)\n",
    "    optimized_fcd_tier.name = 'optimized_fcd'\n",
    "    session['textgrid'].add_tier(optimized_fcd_tier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "mean: 0.8614435366224688 std: 0.04081918949324621\n",
      "backchannels_correctly_categorised\n",
      "mean: 0.5849182344379213 std: 0.25076737876469085\n",
      "stability\n",
      "mean: 0.2914369260583304 std: 0.08822166518997065\n",
      "lag\n",
      "mean: 0.08571070287788207 std: 0.00817481340315245\n"
     ]
    }
   ],
   "source": [
    "for func in [accuracy, backchannels_correctly_categorised, stability, lag]:\n",
    "    print(func.__name__)\n",
    "    vals = list(stat_application_generator(test_set(data), func, 'optimized_fcd'))\n",
    "    print('mean:', np.mean(vals), 'std:', np.std(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the accuracy significantly better than the hand-picked values (evaluated on the test-set)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=0.24778800660262884, pvalue=0.8114098018075939)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_optimized_vals = list(stat_application_generator(test_set(data), accuracy, 'fcd'))\n",
    "optimized_vals = list(stat_application_generator(test_set(data), accuracy, 'optimized_fcd'))\n",
    "stats.ttest_rel(non_optimized_vals, optimized_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't seem like the optimization improves on the test-set. Let's check the train-set, to make sure it does something reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-optimized\n",
      "mean: 0.870213230147201 std: 0.029191274312062226\n",
      "Optimized\n",
      "mean: 0.8892287830008905 std: 0.019463745720531816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-2.978451411880582, pvalue=0.007165853993480536)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_optimized_vals = list(stat_application_generator(train_set(data), accuracy, 'fcd'))\n",
    "optimized_vals = list(stat_application_generator(train_set(data), accuracy, 'optimized_fcd'))\n",
    "print('Non-optimized')\n",
    "print('mean:', np.mean(non_optimized_vals), 'std:', np.std(non_optimized_vals))\n",
    "print('Optimized')\n",
    "print('mean:', np.mean(optimized_vals), 'std:', np.std(optimized_vals))\n",
    "stats.ttest_rel(non_optimized_vals, optimized_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
