{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import audioop\n",
    "import itertools\n",
    "import pathlib\n",
    "import random\n",
    "import subprocess\n",
    "import tempfile\n",
    "import wave\n",
    "\n",
    "import keras.models\n",
    "import numpy as np\n",
    "import tgt\n",
    "import webrtcvad\n",
    "\n",
    "import data_loading\n",
    "import floor_control\n",
    "import settings\n",
    "import skantze_train\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(data_loading.generator(settings.ANNOTATIONS_DIR, settings.AUDIO_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floor tier from annotations (target / annotated floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_unsorted_utterance_intervals(tg, tier_names):\n",
    "    for i, tier in enumerate(tier_names):\n",
    "        for interval in tg.get_tier_by_name(tier).intervals:\n",
    "            yield tgt.core.Interval(\n",
    "                interval.start_time,\n",
    "                interval.end_time,\n",
    "                str(i),\n",
    "            )\n",
    "\n",
    "\n",
    "def _generate_floor_intervals(tg, tier_names):\n",
    "    gen = _generate_unsorted_utterance_intervals(tg, tier_names)\n",
    "    intervals = iter(sorted(gen, key=lambda x: x.start_time))\n",
    "    cur = next(intervals)\n",
    "    while True:\n",
    "        try:\n",
    "            nex = next(intervals)\n",
    "        except StopIteration:\n",
    "            yield cur\n",
    "            break\n",
    "        # Current and next one are same speaker -> merge\n",
    "        if cur.text == nex.text:\n",
    "            cur = tgt.core.Interval(cur.start_time, nex.end_time, cur.text)\n",
    "        # Current ends before next one starts -> output current\n",
    "        elif cur.end_time <= nex.start_time:\n",
    "            yield cur\n",
    "            cur = nex\n",
    "        # Next is completely within current -> ignore it\n",
    "        elif nex.start_time >= cur.start_time and nex.end_time <= cur.end_time:\n",
    "            pass\n",
    "        # Otherwise it's a partial overlap\n",
    "        else:\n",
    "            yield tgt.core.Interval(cur.start_time, nex.start_time, cur.text)\n",
    "            cur = tgt.core.Interval(cur.end_time, nex.end_time, nex.text)\n",
    "            \n",
    "            \n",
    "def calculate_floor_tier_from_annotations(tg, tier_names):\n",
    "    floor_tier = tgt.core.IntervalTier(name='target')\n",
    "    floor_tier.add_intervals(_generate_floor_intervals(tg, tier_names))\n",
    "    return floor_tier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backchannels tier from annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_backchannel(interval):\n",
    "    words = [w.lower() for w in interval.text.split()]\n",
    "    backchannel_words = all(w in settings.BACKCHANNEL_WORDS for w in words)\n",
    "    short_enough = interval.end_time - interval.start_time < settings.MAX_BACKCHANNEL_DURATION\n",
    "    return backchannel_words and short_enough\n",
    "\n",
    "\n",
    "def _generate_backchannel_points(tg, tier_names):\n",
    "    for i, tier_name in enumerate(tier_names):\n",
    "        for interval in tg.get_tier_by_name(tier_name).intervals:\n",
    "            if is_backchannel(interval):\n",
    "                yield tgt.core.Point(time=interval.start_time, text=str(i))\n",
    "\n",
    "\n",
    "def calculate_backchannels_tier_from_annotations(tg, tier_names):\n",
    "    backchannels_tier = tgt.core.PointTier(name='backchannels')\n",
    "    backchannels_tier.add_points(_generate_backchannel_points(tg, tier_names))\n",
    "    return backchannels_tier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floor tier from audio (detected / FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_detection_per_frame_from_wav(\n",
    "    filepath,\n",
    "    buffer_duration,\n",
    "    swap_stereo,\n",
    "    detector_class,\n",
    "    detector_params,\n",
    "):\n",
    "    with wave.open(str(filepath)) as f:\n",
    "        sample_rate = f.getframerate()\n",
    "        sample_width = f.getsampwidth()\n",
    "        buffer_size = int(sample_rate * buffer_duration)\n",
    "\n",
    "        detector_params['sample_rate'] = sample_rate\n",
    "        detector_params['sample_width'] = sample_width\n",
    "        detector_params['buffer_size'] = buffer_size\n",
    "\n",
    "        detector = detector_class(**detector_params)\n",
    "\n",
    "        while True:\n",
    "            fragment = f.readframes(buffer_size)\n",
    "            if len(fragment) != buffer_size * sample_width * f.getnchannels():\n",
    "                break\n",
    "            l = audioop.tomono(fragment, sample_width, 1, 0)\n",
    "            r = audioop.tomono(fragment, sample_width, 0, 1)\n",
    "            if swap_stereo:\n",
    "                l, r = r, l\n",
    "            yield detector.process([l, r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_intervals_from_frames(frames, frame_duration, shift=0):\n",
    "    timed_frames = zip(itertools.count(step=frame_duration), frames)\n",
    "    changes = utils.dedup(timed_frames, key=lambda x: x[1])\n",
    "    for cur, nex in utils.pairwise(changes):\n",
    "        yield tgt.core.Interval(start_time=cur[0] + shift, end_time=nex[0] + shift, text=str(cur[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random floor tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_random_floor_intervals(average_floor_duration):\n",
    "    floor_holder = random.randint(0, 1)\n",
    "    previous_timestamp = 0\n",
    "    while True:\n",
    "        samples = np.random.exponential(average_floor_duration, 100)\n",
    "        timestamps = samples.cumsum() + previous_timestamp\n",
    "        for timestamp in timestamps:\n",
    "            yield tgt.core.Interval(\n",
    "                start_time=previous_timestamp,\n",
    "                end_time=timestamp,\n",
    "                text=str(floor_holder)\n",
    "            )\n",
    "            floor_holder = (floor_holder * -1) + 1\n",
    "            previous_timestamp = timestamp\n",
    "\n",
    "\n",
    "def calculate_random_floor_tier(average_floor_duration, textgrid_duration):\n",
    "    gen = _generate_random_floor_intervals(average_floor_duration)\n",
    "    tier = tgt.core.IntervalTier(name='random')\n",
    "    tier.add_intervals(itertools.takewhile(lambda i: i.end_time < textgrid_duration, gen))\n",
    "    return tier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAD floor tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VadDetector:\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_rate,\n",
    "        vad_mode,\n",
    "        **_,\n",
    "    ):\n",
    "        self._vad = webrtcvad.Vad(vad_mode)\n",
    "        self._sample_rate = sample_rate\n",
    "        self._current_floor_holder = None\n",
    "        \n",
    "    def process(self, fragments):\n",
    "        vad_vals = [self._vad.is_speech(fragment, self._sample_rate) for fragment in fragments]\n",
    "        # Change floor holder when only one is vocalising\n",
    "        if sum(vad_vals) == 1:\n",
    "            self._current_floor_holder = vad_vals.index(True)\n",
    "        return self._current_floor_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(source, target):\n",
    "    subprocess.run([\n",
    "        'ffmpeg',\n",
    "        '-y',  # Overwrite, it will always exist because a temp is created\n",
    "        '-i', source,\n",
    "        '-ar', '48000',\n",
    "        target,\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update TextGrids with calculated tiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotated floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in data:\n",
    "    tg = session['textgrid']\n",
    "    tg.add_tier(calculate_floor_tier_from_annotations(tg, settings.ANNOTATIONS_TIERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotated backchannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in data:\n",
    "    tg = session['textgrid']\n",
    "    tg.add_tier(calculate_backchannels_tier_from_annotations(tg, settings.ANNOTATIONS_TIERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.2 s, sys: 3.43 s, total: 1min 1s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for session in data:\n",
    "    tg = session['textgrid']\n",
    "    audio_filepath = settings.AUDIO_DIR / session['name'] / f'{session[\"name\"]}.wav'\n",
    "    frames_gen = generate_detection_per_frame_from_wav(\n",
    "        audio_filepath,\n",
    "        settings.BUFFER_DURATION,\n",
    "        session['swapped_stereo'],\n",
    "        floor_control.RmsFilterDetector,\n",
    "        {'cutoff_freq': 0.35, 'hysteresis': 0.1},\n",
    "    )\n",
    "    tier = tgt.core.IntervalTier(name='detected')\n",
    "    tier.add_intervals(generate_intervals_from_frames(frames_gen, settings.BUFFER_DURATION))\n",
    "    tg.add_tier(tier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2634707847988693"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_floor_duration = np.mean(\n",
    "    [\n",
    "        i.end_time - i.start_time\n",
    "        for session in data\n",
    "        for i in session['textgrid'].get_tier_by_name('target')\n",
    "    ]\n",
    ")\n",
    "average_floor_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in data:\n",
    "    tg = session['textgrid']\n",
    "    tg.add_tier(calculate_random_floor_tier(average_floor_duration, tg.end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skantze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0828 17:12:31.292941 140257205532288 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0828 17:12:31.315837 140257205532288 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0828 17:12:31.321515 140257205532288 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0828 17:12:31.562888 140257205532288 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0828 17:12:31.563446 140257205532288 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0828 17:12:31.705415 140257205532288 deprecation_wrapper.py:119] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0828 17:12:31.837707 140257205532288 deprecation.py:323] From /home/nagasaki45/code/floor-control/experiments/env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model_0 = keras.models.load_model('model_0.h5')\n",
    "model_1 = keras.models.load_model('model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 41s, sys: 10.4 s, total: 2min 52s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for session in data:\n",
    "    tg = session['textgrid']\n",
    "    intervals = []\n",
    "    for part in session['parts']:\n",
    "        X = np.load(skantze_train.DATA_DIR / f'X-{session[\"name\"]}-{part[\"name\"]}.npy')\n",
    "\n",
    "        batch_generator = skantze_train.BatchGenerator(\n",
    "            X,\n",
    "            np.zeros(len(X)),\n",
    "            skantze_train.SEQUENCE_LENGTH,\n",
    "            skantze_train.PREDICTION_LENGTH,\n",
    "            skantze_train.BATCH_SIZE,\n",
    "        )\n",
    "        model_0_predictions = model_0.predict_generator(batch_generator)\n",
    "        model_1_predictions = model_1.predict_generator(batch_generator)\n",
    "        predictions = np.vstack([model_0_predictions[:, 0], model_1_predictions[:, 0]])\n",
    "        floor_holder = predictions.T.argmax(axis=1)\n",
    "\n",
    "        intervals += list(\n",
    "            generate_intervals_from_frames(\n",
    "                floor_holder,\n",
    "                frame_duration=0.05,\n",
    "                shift=part['start_time'],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    tier = tgt.core.IntervalTier(name='skantze')\n",
    "    tier.add_intervals(intervals)\n",
    "    tg.add_tier(tier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 3.47 s, total: 1min 31s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for session in data:\n",
    "    tg = session['textgrid']\n",
    "    audio_filepath = settings.AUDIO_DIR / session['name'] / f'{session[\"name\"]}.wav'\n",
    "    with tempfile.NamedTemporaryFile(suffix='.wav') as tf:\n",
    "        upsample(str(audio_filepath.resolve()), tf.name)\n",
    "        frames_gen = generate_detection_per_frame_from_wav(\n",
    "            tf.name,\n",
    "            settings.BUFFER_DURATION,\n",
    "            session['swapped_stereo'],\n",
    "            VadDetector,\n",
    "            {'vad_mode': 3},\n",
    "        )\n",
    "        tier = tgt.core.IntervalTier(name='vad')\n",
    "        tier.add_intervals(generate_intervals_from_frames(frames_gen, settings.BUFFER_DURATION))\n",
    "        tg.add_tier(tier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export textgrid for manual observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in data:\n",
    "    with open(pathlib.Path('tmp') / f'{session[\"name\"]}.textgrid', 'w') as f:\n",
    "        f.write(tgt.io.export_to_long_textgrid(session['textgrid']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_application_generator(data, stat_func, candidate):\n",
    "    i = 0\n",
    "    for session in data:\n",
    "        tg = session['textgrid']\n",
    "        for part in session['parts']:\n",
    "            if (i % 4 == 0):  # Only test-set\n",
    "                yield stat_func(tg, tg.get_tier_by_name(candidate), part['start_time'], part['end_time'])\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 - agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agreement(tg, candidate_tier, start, end):\n",
    "    total = 0\n",
    "    hits = 0\n",
    "    target_tier = tg.get_tier_by_name('target')\n",
    "    for time in np.arange(start, end, 0.1):\n",
    "        target = target_tier.get_annotations_by_time(time)\n",
    "        if target:\n",
    "            detected = candidate_tier.get_annotations_by_time(time)\n",
    "            if detected and detected[0].text == target[0].text:\n",
    "                hits += 1\n",
    "            total += 1\n",
    "    return hits / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected agreement\n",
      "mean: 0.8644762165956857 std: 0.024724106725840835\n",
      "random agreement\n",
      "mean: 0.5048602002907447 std: 0.02263357847568976\n",
      "vad agreement\n",
      "mean: 0.7019965078029801 std: 0.06316885551288656\n",
      "skantze agreement\n",
      "mean: 0.5331396491162868 std: 0.06345740365096404\n",
      "CPU times: user 28.3 s, sys: 0 ns, total: 28.3 s\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for candidate in settings.COMPARABLE_TIERS:\n",
    "    print(candidate, 'agreement')\n",
    "    vals = list(stat_application_generator(data, agreement, candidate))\n",
    "    print('mean:', np.mean(vals), 'std:', np.std(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2 - backchannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backchannels_correctly_categorised(tg, candidate_tier, start, end):\n",
    "    total = 0\n",
    "    hits = 0\n",
    "    bc_tier = tg.get_tier_by_name('backchannels')\n",
    "    for bc in bc_tier.get_annotations_between_timepoints(start, end):\n",
    "        floor_at_bc = candidate_tier.get_annotations_by_time(bc.time)\n",
    "        if floor_at_bc:\n",
    "            if floor_at_bc[0].text != bc.text:\n",
    "                hits += 1\n",
    "            total += 1\n",
    "    return hits / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected backchannels correctly categorised\n",
      "mean: 0.7922724314742816 std: 0.10568349102940862\n",
      "random backchannels correctly categorised\n",
      "mean: 0.5935503804781557 std: 0.18215760065878636\n",
      "vad backchannels correctly categorised\n",
      "mean: 0.6561874390236582 std: 0.149850841247541\n",
      "skantze backchannels correctly categorised\n",
      "mean: 0.634582046549928 std: 0.17943228040203382\n"
     ]
    }
   ],
   "source": [
    "for candidate in settings.COMPARABLE_TIERS:\n",
    "    print(candidate, 'backchannels correctly categorised')\n",
    "    vals = list(stat_application_generator(data, backchannels_correctly_categorised, candidate))\n",
    "    print('mean:', np.mean(vals), 'std:', np.std(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 - stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor_holder_changes(tg, candidate_tier, start_time, end_time):\n",
    "    gen = (i.text for i in candidate_tier.get_annotations_between_timepoints(start_time, end_time))\n",
    "    items = utils.dedup(gen)\n",
    "    return len(list(items)) - 1  # number of changes is number of values minus 1\n",
    "\n",
    "\n",
    "def stability(tg, candidate_tier, start_time, end_time):\n",
    "    annotated_floor = tg.get_tier_by_name('target')\n",
    "    annotated_floor_changes = floor_holder_changes(tg, annotated_floor, start_time, end_time)\n",
    "    candidate_floor_changes = floor_holder_changes(tg, candidate_tier, start_time, end_time)\n",
    "    return annotated_floor_changes / candidate_floor_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected stability\n",
      "mean: 0.9287108417871082 std: 0.21944462860850766\n",
      "random stability\n",
      "mean: 0.8968191785368049 std: 0.3281678098472433\n",
      "vad stability\n",
      "mean: 0.21358132690750747 std: 0.07577958923744672\n",
      "skantze stability\n",
      "mean: 0.15937797604730697 std: 0.0379461612731586\n"
     ]
    }
   ],
   "source": [
    "for candidate in settings.COMPARABLE_TIERS:\n",
    "    print(candidate, 'stability')\n",
    "    vals = list(stat_application_generator(data, stability, candidate))\n",
    "    print('mean:', np.mean(vals), 'std:', np.std(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4 - lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag(tg, candidate_tier, start_time, end_time):\n",
    "    lags = []\n",
    "    visited_target_intervals = set()\n",
    "    target_tier = tg.get_tier_by_name('target')\n",
    "    for candidate_interval in candidate_tier.intervals:\n",
    "        target_intervals = target_tier.get_annotations_by_time(candidate_interval.start_time)\n",
    "        if target_intervals:\n",
    "            target_interval = target_intervals[0]\n",
    "            if (\n",
    "                target_interval.text == candidate_interval.text and\n",
    "                target_interval not in visited_target_intervals\n",
    "            ):\n",
    "                lags.append(candidate_interval.start_time - target_interval.start_time)\n",
    "            visited_target_intervals.add(target_interval)\n",
    "    return np.mean(lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected lag\n",
      "mean: 0.41077566962461864 std: 0.04000523491024262\n",
      "random lag\n",
      "mean: 1.791989110725945 std: 0.4134349961795376\n",
      "vad lag\n",
      "mean: 0.4767208722773748 std: 0.09355363374067974\n",
      "skantze lag\n",
      "mean: 1.2944193514103752 std: 0.9609737180907929\n"
     ]
    }
   ],
   "source": [
    "for candidate in settings.COMPARABLE_TIERS:\n",
    "    print(candidate, 'lag')\n",
    "    vals = list(stat_application_generator(data, lag, candidate))\n",
    "    print('mean:', np.mean(vals), 'std:', np.std(vals))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
